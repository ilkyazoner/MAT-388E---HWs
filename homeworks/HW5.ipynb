{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5\n",
    "\n",
    "For this homework, we are going to work with [*Indoor User Movement Prediction from RSS data*](https://archive.ics.uci.edu/ml/datasets/Indoor+User+Movement+Prediction+from+RSS+data) dataset from UCI.  The homework is due Friday, December 21st midnight. \n",
    "\n",
    "## Task 1\n",
    "\n",
    "Download the dataset and unzip it in under a subdirectory of `data` folder named `rss_data`.\n",
    "\n",
    "The files we are interested is in the subfolder `dataset`.  Each of these files whose names that start with `MovementAAL_RSS_` contain data collected from indivuduals. Each of these files represent a single data point.  There are 314 of these files, and hence, you have 314 data points.  Each file has 4 columns but the number of rows change from file to file.  \n",
    "\n",
    "There is also a file named `MovementALL_target.csv` in that folder. This file tells us the class each of these measurements are assigned. Some of these measurements are labelled with +1 and some are labelled with -1.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Construct a SVM model that separates +1 labelled data points from -1 data points.  You must first solve the problem that these datapoints do not have the same number of rows even though they all have the same number of columns. \n",
    "\n",
    "## Task 3\n",
    "\n",
    "Using [Keras](https://keras.io/getting-started/sequential-model-guide/) write a neural network model that separates +1 labelled data points from -1 data points.\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. You must document each step of your tasks: what are you doing, why are you doing it, what problems you encountered and how you solved it.  All of these must be explained and documented.  Solutions without sufficient documentations will be penalized accordingly. 50% of your points will come from your code, while the other 50% will come from your explanations.\n",
    "\n",
    "1. You can use MS Excel to inspect the files, but loading them up to python using pandas and inspecting them there under jupyter is easier.\n",
    "\n",
    "3. Put the data in a separate subfolder of your `data` folder and rename it `rss_data`. I'll take points off if the data is not saved under the correct place.\n",
    "\n",
    "1. For both of Task 2 and Task 3, you must split your data into a train and test set, and then evaluate the accuracy of your model on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read the MovementAAL_target.csv file which includes +1 and -1 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetset = pd.read_csv(r'C:\\Users\\ONER\\Desktop\\MAT388E\\data\\rss_data\\dataset\\MovementAAL_target.csv', names=('sequence_ID', 'class_label'), skiprows=(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read the MovementAAL_RSS_ files. There is 314 files, 314 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(seq_id):\n",
    "    return pd.read_csv(r'C:\\Users\\ONER\\Desktop\\MAT388E\\data\\rss_data\\dataset\\MovementAAL_RSS_%s.csv' % seq_id, names=('RSS_anchor1', 'RSS_anchor2','RSS_anchor3', 'RSS_anchor4'), skiprows=(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define x and y values above.\n",
    "\n",
    "The problem was the length of vectors doesn't have same length. I couldn't fix that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(df):\n",
    "    frames = []\n",
    "    target = []\n",
    "    for idx, row in df.iterrows():\n",
    "        data = dataset(row['sequence_ID'])\n",
    "        frames.append(data)\n",
    "        arr = [row['class_label']] * len(data)\n",
    "        target += arr\n",
    "        \n",
    "    return pd.concat(frames), target\n",
    "\n",
    "data_test, target_test = create_data(targetset)\n",
    "\n",
    "X = data_test.get_values()\n",
    "y = target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs, test_xs, train_ys, test_ys = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='rbf', gamma=2.0)\n",
    "classifier.fit(train_xs,train_ys)\n",
    "\n",
    "predicted_ys = classifier.predict(test_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 812  563]\n",
      " [ 337 1588]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(test_ys,predicted_ys))\n",
    "accuracy_score(test_ys,predicted_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=1)\n",
    "scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "scalarX.fit(X)\n",
    "scalarY.fit(y.reshape(100,1))\n",
    "X = scalarX.transform(X)\n",
    "y = scalarY.transform(y.reshape(100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.9739 - acc: 0.0100\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 71us/step - loss: 1.5767 - acc: 0.0100\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.4825 - acc: 0.0100\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.4168 - acc: 0.0100\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.3683 - acc: 0.0100\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.3297 - acc: 0.0100\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 1.2963 - acc: 0.0100\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2681 - acc: 0.0100\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 100us/step - loss: 1.2434 - acc: 0.0100\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.2210 - acc: 0.0100\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2005 - acc: 0.0100\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.1828 - acc: 0.0100\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.1661 - acc: 0.0100\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.1508 - acc: 0.0100\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.1360 - acc: 0.0100\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.1228 - acc: 0.0100\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.1098 - acc: 0.0100\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 100us/step - loss: 1.0977 - acc: 0.0100\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 100us/step - loss: 1.0861 - acc: 0.0100\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.0752 - acc: 0.0100\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 1.0645 - acc: 0.0100\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.0543 - acc: 0.0100\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.0441 - acc: 0.0100\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.0350 - acc: 0.0100\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.0258 - acc: 0.0100\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.0166 - acc: 0.0100\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.0075 - acc: 0.0100\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.9990 - acc: 0.0100\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.9911 - acc: 0.0100\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9829 - acc: 0.0100\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.9751 - acc: 0.0100\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.9673 - acc: 0.0100\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9595 - acc: 0.0100\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9525 - acc: 0.0100\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.9454 - acc: 0.0100\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9384 - acc: 0.0100\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.9317 - acc: 0.0100\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9253 - acc: 0.0100\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.9189 - acc: 0.0100\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9127 - acc: 0.0100\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.9067 - acc: 0.0100\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.9009 - acc: 0.0100\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.8951 - acc: 0.0100\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.8895 - acc: 0.0100\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.8839 - acc: 0.0100\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.8781 - acc: 0.0100\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 140us/step - loss: 0.8727 - acc: 0.0100\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.8673 - acc: 0.0100\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.8622 - acc: 0.0100\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.8571 - acc: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160f3ddcb70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
